# -*- coding: utf-8 -*-
"""Solver.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SMryw3FDFmolrf7NpawpT9TdoQ7KCTf7
"""

import os
from google.colab import drive
drive.mount('/content/drive')

os.chdir('./drive/My Drive')
!ls

from abc import ABC, abstractmethod
import numpy as np
import keras
from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, AveragePooling2D, Flatten, InputLayer
from keras import Sequential
import pandas as pd

import pandas as pd
df=pd.DataFrame({'TaskType': 'classification', 'categories': [('cats', 'mice')], 'pipeline' : 'ResNet50', 
                 'augmen_params' : [{'preprocessing_function': keras.applications.resnet.preprocess_input, 'horizontal_flip' : True}],
                 'optimizer': 'Adam', 'batch_size' : 32, 'epoch' : 1 , 'loss' : 'binary_crossentropy', 'metrics':'accuracy', 'additional_params' : [{}] , 'achieved accuracy' : 0.91} )
df.to_csv('ModelTrainingHistory.csv')
df

from abc import ABC, abstractmethod
import numpy as np
import keras
from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, AveragePooling2D, Flatten, InputLayer
from keras import Sequential
import pandas as pd


# Входные данные для задачи
data = { 'address': './Databases/Kaggle_CatsVSDogs', 'classes': ('cats','dogs')}

# Глобал rules задаёт список приёмов
rules = []


def rule(cls):
    global rules
    rules.append(cls())
    return cls


class Task:
    '''
    Базовый тип задачи
    '''

    def __init__(self, type, goals):
        self._type = type  # тип задачи
        self.goals = goals  # множество целей

    @property
    def type(self):
        return self._type


class ModelTask(Task):
    '''
    Тип задачи на создание модели нейронной сети
    Имеет базовую цель 'model', дающую указание приёмам
    создать модель нейронной сети и выдать её в качестве ответа
    '''

    def __init__(self, data, Ttype, goals=()):
        self.data = data
        self.taskType=Ttype
        self.model={'pipeline' : ''}
        self.model_architecture=()
        super().__init__('model', {'model'} | set(goals))


class State:
    '''
    Базовый тип состояния решения задачи
    '''

    def __init__(self, task):
        self.answer = None  # ответ на решение задачи
        self.task = task  # текущая решаемая задача


class Rule(ABC):
    '''
    Базовый тип приёма
    Имеет два обязательных метода can_apply и apply
    '''

    @abstractmethod
    def can_apply(self, state: State):
        '''
        Проверка целесообразности применения приёма
        Returns:
        bool - признак целесообразности применения приёма
        '''
        pass

    @abstractmethod
    def apply(self, state: State):
        '''
        Применение приёма
        '''
        pass

@rule
class IsDatabaseAvailable(Rule):

  def can_apply(self, state):
    return('train' or 'test' in state.task.goals)

  def apply(self, state):
    print('Available Data')
    state.dataAvail=(data!=[])


@rule
class CheckingModelHistory(Rule):

  def can_apply(self, state):
    return('train' in state.task.goals and hasattr(state, 'dataAvail'))

  def apply(self, state):
    print('Checking')
    state.df = pd.read_csv('./ModelTrainingHistory.csv', sep=',')
    for i in range(len(state.df)):
       if df.iloc[i]['TaskType']==state.task.taskType:
         state.task.model['pipeline']=state.df.iloc[i]['pipeline']
         state.task.augmen_params=state.df.iloc[i]['augmen_params']

         state.task.train_params={}
         state.task.train_params['batch_size'] =state.df.iloc[i]['batch_size']
         state.task.train_params['optimizer'] =state.df.iloc[i]['optimizer']
         state.task.train_params['epoch'] =state.df.iloc[i]['epoch']
         state.task.train_params['loss'] =state.df.iloc[i]['loss']
         state.task.train_params['metrics'] =state.df.iloc[i]['metrics']
         break
    state.task.training_str=True
        

@rule
class MakeSequentialModel(Rule):

    def can_apply(self, state):
        return ('model' in state.task.goals and 'train' in state.task.goals and state.task.training_str==True )

    def apply(self, state):
      
      print('Model')
      dim = (224,224,3)
      model = Sequential()
      model.add(InputLayer(input_shape=dim))
      model.add(Conv2D(filters=64, kernel_size=(7, 7), strides=2, activation="relu"))
      model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))
      model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, activation="relu"))
      model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=2, activation="relu"))
      model.add(AveragePooling2D(pool_size=(2, 2)))
      model.add(Flatten())
      model.add(Dense(64))
      model.add(Dense(1, activation="sigmoid"))
      state.task.model_architecture = model


@rule
class DataGenetator(Rule):
    '''
    Приём для создания генератора изображений с заданными параметрами аугментации
    '''

    def can_apply(self, state):
      return ('train' in state.task.goals  and hasattr(state, 'dataAvail'))

    def apply(self, state):

      print('DataGen')
      state.dataGen=keras.preprocessing.image.ImageDataGenerator(state.task.augmen_params)
      print(state.dataGen)
      state.Train_generator=state.dataGen.flow_from_directory(directory= state.task.data['address']+'/train',
                         target_size=(224,224), class_mode='binary', batch_size=state.task.train_params['batch_size'])
      state.Test_generator=state.dataGen.flow_from_directory(directory= state.task.data['address']+'/test',
                         target_size=(224,224), class_mode='binary', batch_size=state.task.train_params['batch_size'])


@rule
class FitModel(Rule):


    def can_apply(self, state):
        return ('train' in state.task.goals  and hasattr(state, 'dataAvail')  and hasattr(state, 'dataGen')   and hasattr(state.task, 'model_architecture'))

    def apply(self, state):
        print('training')
        #preparation for training
        state.task.model_architecture.compile(optimizer=state.task.train_params['optimizer'], loss=state.task.train_params['loss'], 
                           metrics=[state.task.train_params['metrics']])
        
        training
        state.task.model_architecture.fit_generator(generator=state.Train_generator, steps_per_epoch=(len(state.Train_generator.filenames) // state.task.train_params['batch_size']), 
                 epochs=state.task.train_params['epoch'])
        

        scores = state.task.model_architecture.evaluate_generator(state.Test_generator, steps=None,verbose=1 )


        state.answer='Trained'
        new_row=({'TaskType': state.task.taskType, 'categories': [state.task.data['classes']], 'pipeline' : state.task.model['pipeline'], 
                 'augmen_params' : [state.task.augmen_params], 'optimizer': state.task.train_params['optimizer'], 'batch_size' : state.task.train_params['batch_size'],
                  'epoch' : state.task.train_params['epoch'] , 'loss' : state.task.train_params['loss'], 'metrics': state.task.train_params['metrics'],
                  'additional_params' : [{}] , 'achieved accuracy' : 0.92} )
        state.df=state.df.append(new_row, ignore_index=True)
        state.df.to_csv('NEW.csv')



def solve(task: Task, rules):
    '''
    Базовая функция решения задачи
    '''
    state = State(task)
    pos = 0
    k=0
    print('rules', rules)
    while state.answer is None and k!=100:
        if rules[pos].can_apply(state):
            rules[pos].apply(state)
        pos = (pos + 1) % len(rules)
        k+=1
    return state.answer


# Создаём и решаем задачу создания модели нейронной сети
task = ModelTask(data, Ttype='classification', goals={'train', '0.9'})
model = solve(task, rules)
