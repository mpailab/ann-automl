
ANN-AutoML
==========

Библиотека для автоматического построения моделей машинного обучения для задачи классификации изображений.
Позволяет автоматически подбирать гиперпараметры модели и обучать (или дообучать) модели на различных наборах данных.

Позволяет обучать нейронные сети без знания Python через веб-интерфейс.

Базовые примеры использования
-----------------------------

Запуск графического интерфейса
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Из корневой папки проекта запустить команду:

.. code-block:: bash

   panel serve launch.py --show

В открывшемся окне браузера есть несколько вкладок, в которых можно задавать параметры для обучения нейронной сети и
наблюдать за ее обучением.


#. Вкладка "Базы данных" позволяет выбрать одну или несколько баз данных, 
   которые будут использоваться для обучения нейронной сети.
#. Вкладка "Параметры обучения" позволяет просматривать и менять параметры обучения нейронной сети.
#. Вкладка "Обучение" позволяет запустить обучение нейронной сети, просматривать логи и графики обучения.
#. Вкладка "История" позволяет просматривать историю обучения нейронных сетей и скачивать обученные модели.

Запуск обучения командной на естественном языке
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Для работы в этом режиме необходимо, чтобы на компьютере имеется видеокарта с размером памяти не менее 24 ГБ.
Также требуется дополнительно установить PyTorch и HuggingFace Transformers.

Из командной строки
~~~~~~~~~~~~~~~~~~~
Запрос передаётся в качестве аргумента скрипта launch_lm.py, например:

.. code-block:: bash

   python3 launch_lm.py "Create model that classifies vehicles. Time for training is 20 minutes"

Рекомендуется писать запросы на английском языке, хотя некоторые запросы на русском языке модель также понимает.

Для преобразования запроса на естественном языке в параметры функции обучения
используется CodeGen-6B-multi (https://huggingface.co/docs/transformers/model_doc/codegen).
Кроме того, для выделения классов объектов из базы данных,
относящихся к запросу пользователя, используется
модель FLAN-T5 XL (https://huggingface.co/google/flan-t5-xl).

Через telegram чат-бота
~~~~~~~~~~~~~~~~~~~~~~~
Чтобы запустить обучение через telegram чат-бота, необходимо:

#. Создать telegram бота и получить его токен.
#. Запустить бота командой:

   .. code-block:: bash

      python3 bot.py

#. По запросу ввести токен бота в командной строке.
#. Создать telegram чат с ботом и при необходимости запретить включать бота в другие чаты
   (чтобы бот не мог получать сообщения от произвольных пользователей).

Чтобы вветси запрос на обучение, достаточно просто отправить его боту сообщением.
Также у бота имеются следующие команды:

#. **/stop** - остановить обучение и отправить текущий результат, если он есть.
#. **/cancel** - отменить обучение. В этом случае все результаты будут удалены.
#. **/plot** - отправить график текущего обучения или последнего обучения, если оно было остановлено.
#. **/accuracy** - отправить точность текущего обучения или последнего обучения, если оно было остановлено.
#. **/emulation on/off** - включить/выключить эмуляцию обучения. При включённой эмуляции работает только
   преобразование запроса в параметры функции, можно проверить работу языковых моделей без запуска реального обучения.
#. **/debug** - отправлять внутреннюю выдачу программы обучения в чат (для отладки без прямого доступа к серверу).
#. **/echo** - тестовая команда, отправляет сообщение обратно. Используется для проверки доступности бота.

Запуск обучения из Python
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

   from ann_automl.core.nn_auto import create_classification_model
   categories = ['car', 'airplane', 'bicycle']
   model = create_classification_model(categories, output_dir='classifier', target_accuracy=0.9, time_limit=3600*24)

Это запустит обучение нейронной сети, которая будет классифицировать 
изображения на 3 класса: 'car', 'airplane', 'bicycle'.
Обучение и подбор гиперпараметров будет продолжаться до тех пор, 
пока точность не достигнет 0.9 или не пройдет 1 день.
После обучения модель и скрипт для запуска будут сохранены в папку 'classifier'.

После того, как модель обучена, ее можно использовать из папки classifier (которая была указана в параметре output_dir) 
для классификации изображений:


#. 
   Классификация изображения из файла:

   .. code-block:: bash

       python3 classifier.py --image_path /path/to/image.jpg

   На экран будет выведено имя класса, к которому относится изображение, 
   а также уверенность принадлежности к этому классу.

#. 
   Сортировка изображений из директории по классам:

   .. code-block:: bash

       python3 classifier.py --image_path /path/to/images/ --out_dir /path/to/output/ --clear_out_dir --threshold 0.6

   В этом случае изображения из директории '/path/to/images/', которые классифицируются с уверенностью больше 0.6,
   будут отсортированы по классам в директорию '/path/to/output/'. 

Для получения списка всех доступных параметров запустите:

.. code-block:: bash

   python3 classifier.py --help


Установка и настройка пакета
----------------------------

Установка
^^^^^^^^^

Для установки пакета нужно запустить команду

.. code-block:: bash

    python setup.py install


Для использования описанных выше интерфейсов не обязательно устанавливать пакет.
Достаточно выкачать репозиторий командой

.. code-block:: bash

    git clone https://github.com/mpailab/ann-automl.git

и запускать скрипты из папки ann_automl.

Настройка
^^^^^^^^^

Для корректной работы пакета необходимо:

#. скачать датасеты, которые будут использоваться для обучения моделей, а именно:

   - Kaggle dataset, https://www.kaggle.com/c/dogs-vs-cats/data.
   - Coco dataset: http://cocodataset.org/#download
   - ImageNet dataset (опционально, требуется регистрация): http://www.image-net.org/download-images

#. запустить инициализацию базы данных при помощи команды python3 init_db.py --out datasets.sqlite



Структура проекта
-----------------

В проект входят следующие компоненты:


#. Пакет ann_automl и система установки, к ней относятся файлы setup.py, setup.cfg, MANIFEST.in,
   requirements.txt.
#. Набор тестов в папке **tests**
#. Набор примеров в папке **examples**
#. Данные для обучения нейронных сетей в папке **data**\ , включая:

   #. стандартные архитектуры нейронных сетей (data/architectures) 
   #. обученные нейронные сети (data/trainedNN), в этой папке:

      * для каждого запуска обучения создаётся подпапка со следующими файлами:

        * Обученная модель (best_weights.h5)
        * Её схема (.png)
        * История обучения (.csv)
        * Результаты тестирования (.csv)
        * Конфигурация обучения (.json)

      * для каждого запуска подбора гиперпараметров создаётся подпапка со следующими файлами:

        * История подбора гиперпараметров (.csv)
        * Конфигурация подбора гиперпараметров (.json)
        * Подпапки с результатами обучения нейронных сетей, созданными в ходе подбора гиперпараметров

#. Вспомогательные скрипты в папке **scripts** для подготовки баз данных и их преобразованию в удобный формат  
#. Файлы для генерации документации в папке **docs**
#. Скрипты для запуска системы через различные интерфейсы:

   - launch.py - запуск системы через веб-интерфейс (основной интерфейс)
   - launch_lm.py - запуск обучения из командной строки с запросом на естественном языке, например
   - Интерфейс для Jupyter Notebook (scripts/jupyter_interface.py)

Для работы системы также необходимо наличие следующих файлов и папок:


#. Папка **datasets** с файлами для обучения нейронных сетей.
   Для работы системы рекомендуется, чтобы были доступны 3 базы:

   * Kaggle_CatsVSDogs
   * COCO dataset
   * imagenet

#. Папка **data/architectures** с файлами с дополнительных архитектур нейронных сетей, которые планируется использовать.
   и которые не входят в стандартный набор keras.applications.

Пакет ann_automl имеет следующие подмодули:

#. **core** -- ядро системы, работа с нейронными сетями и обучающими выборками
#. **nnplot** -- модуль для визуализации нейронных сетей, рисования различных графиков, связанных с обучением нейронных сетей
#. **gui** -- графический веб-интерфейс для работы с системой
#. **lm** -- функции работы с запросами на естественном языке
#. **utils** -- библиотека различных вспомогательных функций общего назначения
