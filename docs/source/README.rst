
ANN-AutoML
==========

Библиотека для автоматического построения моделей машинного обучения для задачи классификации изображений.
Позволяет автоматически подбирать гиперпараметры модели и обучать (или дообучать) модели на различных наборах данных.

Позволяет обучать нейронные сети без знания Python через веб-интерфейс.

Базовые примеры использования
-----------------------------

Запуск графического интерфейса
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Из корневой папки проекта запустить команду:

.. code-block:: bash

   panel serve launch.py --show

В открывшемся окне браузера есть несколько вкладок, в которых можно задавать параметры для обучения нейронной сети и
наблюдать за ее обучением.


#. Вкладка "Базы данных" позволяет выбрать одну или несколько баз данных, 
   которые будут использоваться для обучения нейронной сети.
#. Вкладка "Параметры обучения" позволяет просматривать и менять параметры обучения нейронной сети.
#. Вкладка "Обучение" позволяет запустить обучение нейронной сети, просматривать логи и графики обучения.
#. Вкладка "История" позволяет просматривать историю обучения нейронных сетей и скачивать обученные модели.

Запуск обучения командной на естественном языке
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Для работы в этом режиме необходимо, чтобы на компьютере имеется видеокарта с размером памяти не менее 24 ГБ.
Также требуется дополнительно установить PyTorch и HuggingFace Transformers.

Из командной строки
~~~~~~~~~~~~~~~~~~~
Запрос передаётся в качестве аргумента скрипта launch_lm.py, например:

.. code-block:: bash

   python3 launch_lm.py "Create model that classifies vehicles. Time for training is 20 minutes"

Рекомендуется формулировать запросы на английском языке, хотя некоторые запросы на русском языке модель также понимает.

Для преобразования запроса на естественном языке в параметры функции обучения
используется CodeGen-6B-multi (https://huggingface.co/docs/transformers/model_doc/codegen).
Кроме того, для выделения классов объектов из базы данных,
относящихся к запросу пользователя, используется
модель FLAN-T5 XL (https://huggingface.co/google/flan-t5-xl).

Через telegram чат-бота
~~~~~~~~~~~~~~~~~~~~~~~
Чтобы запустить обучение через telegram чат-бота, необходимо:

#. Создать telegram бота и получить его токен.
#. Запустить бота командой:

   .. code-block:: bash

      python3 bot.py

#. По запросу ввести токен бота в командной строке.
#. Создать telegram чат с ботом и при необходимости запретить включать бота в другие чаты
   (чтобы бот не мог получать сообщения от произвольных пользователей).

Чтобы вветси запрос на обучение, достаточно просто отправить его боту сообщением.
Также у бота имеются следующие команды:

#. **/stop** - остановить обучение и отправить текущий результат, если он есть.
#. **/cancel** - отменить обучение. В этом случае все результаты будут удалены.
#. **/plot** - отправить график текущего обучения или последнего обучения, если оно было остановлено.
#. **/accuracy** - отправить точность текущего обучения или последнего обучения, если оно было остановлено.
#. **/emulation on/off** - включить/выключить эмуляцию обучения. При включённой эмуляции работает только
   преобразование запроса в параметры функции, можно проверить работу языковых моделей без запуска реального обучения.
#. **/debug** - отправлять внутреннюю выдачу программы обучения в чат (для отладки без прямого доступа к серверу).
#. **/echo** - тестовая команда, отправляет сообщение обратно. Используется для проверки доступности бота.

Запуск обучения из Python
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

   from ann_automl.core.nn_auto import create_classification_model
   categories = ['car', 'airplane', 'bicycle']
   model = create_classification_model(categories, output_dir='classifier', target_accuracy=0.9, time_limit=3600*24)

Это запустит обучение нейронной сети, которая будет классифицировать 
изображения на 3 класса: 'car', 'airplane', 'bicycle'.
Обучение и подбор гиперпараметров будет продолжаться до тех пор, 
пока точность не достигнет 0.9 или не пройдет 1 день.
После обучения модель и скрипт для запуска будут сохранены в папку 'classifier'.

После того, как модель обучена, ее можно использовать из папки classifier (которая была указана в параметре output_dir) 
для классификации изображений:


#. 
   Классификация изображения из файла:

   .. code-block:: bash

       python3 classifier.py --image_path /path/to/image.jpg

   На экран будет выведено имя класса, к которому относится изображение, 
   а также уверенность принадлежности к этому классу.

#. 
   Сортировка изображений из директории по классам:

   .. code-block:: bash

       python3 classifier.py --image_path /path/to/images/ --out_dir /path/to/output/ --clear_out_dir --threshold 0.6

   В этом случае изображения из директории '/path/to/images/', которые классифицируются с уверенностью больше 0.6,
   будут отсортированы по классам в директорию '/path/to/output/'. 

Для получения списка всех доступных параметров запустите:

.. code-block:: bash

   python3 classifier.py --help


Установка и настройка пакета
----------------------------

Установка
^^^^^^^^^

Для установки пакета нужно запустить команду

.. code-block:: bash

    python setup.py install


Для использования описанных выше интерфейсов не обязательно устанавливать пакет.
Достаточно выкачать репозиторий командой

.. code-block:: bash

    git clone https://github.com/mpailab/ann-automl.git

и запускать скрипты из папки ann_automl.

Настройка
^^^^^^^^^

Для корректной работы пакета необходимо создать базу данных и добавить в неё датасеты,
которые будут использоваться для обучения моделей.
Есть несколько способов добавлять датасеты.

Инициализация БД с датасетами ImageNet, Coco и Kaggle
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Если будут использоваться датасеты Kaggle cats vs dogs,
Coco и ImageNet, их требуется скачать вручную и добавить
в базу данных в первую очередь. Для этого нужно:

#. Cкачать датасеты и положить в директории по умолчанию, а именно:

   - Kaggle Cats vs Dogs

     - Создать директорию ``./datasets/Kaggle``
     - Скачать датасет с сайта https://www.kaggle.com/c/dogs-vs-cats
     - Распаковать архив, директория train должна быть в созданной ранее директории ``./datasets/Kaggle``

   - COCO 2017

     - Создать директорию ``./datasets/COCO2017``
     - Скачать датасет COCO2017 с официального сайта https://cocodataset.org/#home,
       либо воспользоваться скриптом https://gist.github.com/mkocabas/a6177fc00315403d31572e17700d7fd9
     - Переместить распакованный датасет в директорию ``./datasets/COCO2017`` так,
       чтобы директория содержала две поддиректории ``images``, ``annotations`` (содержатся в COCO2017)

   - ImageNet (требуется регистрация)

     - Создать директорию ``./datasets/imagenet``
     - Скачать датасет ImageNet с официального сайта https://image-net.org/download.php
     - Распаковать данные в диекторию ``./datasets/imagenet`` (после разархивации директория
       imagenet должна содержать поддиректории annotations, ILSVRC2012_img_train)

#. Запустить инициализацию базы данных при помощи команды python3 init_db.py --db datasets.sqlite --init default

На данный момент только для этих баз имеется соответствие категорий, а также информация о надкатегориях.
При добавлении датасетов  другими способами, могут появиться альтернативные названия для одинаковых категорий.

Добавление датасета из tensorflow_datasets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

В системе есть возможность добавлять в базу данных датасеты
для классификации изображений из **tensorflow datasets** (https://www.tensorflow.org/datasets/catalog/overview#image_classification_2).
Для этого нужно запустить скрипт:

.. code-block:: bash

   python3 init_db.py --db datasets.sqlite --add_tfds <tf_dataset_name> [--name <dataset_name>]

где ``<tf_dataset_name>`` - имя датасета, по которому он ищется в **tensorflow datasets**,
а ``<dataset_name>`` - имя датасета в базе данных. По умолчанию ``<dataset_name>`` равен ``<tf_dataset_name>``.
Например, датасет inaturalist2021 можно добавить в автоматическом режиме,
выполнив команду ``python init_db.py --db datasets.sqlite --add_tfds inaturalist2021 --name inaturalist``.

Добавление датасета из директории с вложенными поддиректориями
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

В системе есть возможность добавлять использовать разбиение файлов по поддиректориям в качестве разметки.
В этом случае имя поддиректории будет использоваться как метка класса.

Для добавления датасета из директории с вложенными поддиректориями нужно выполнить команду:

.. code-block:: bash

   python init_db.py --db datasets.sqlite --add_dir_ds <path_to_dir> --name <dataset_name>

где

- ``<dataset_name>`` - имя датасета, по которому он будет доступен в базе данных;
- ``<path_to_dir>`` - путь к корневой директории датасета; важно, что структура должна быть двухуровневой,
  т.е. в директории должны быть поддиректории, в которых находятся файлы с изображениями.

Структура проекта
-----------------

В проект входят следующие компоненты:


#. Пакет ann_automl и система установки, к ней относятся файлы setup.py, setup.cfg, MANIFEST.in,
   requirements.txt.
#. Набор тестов в папке **tests**
#. Набор примеров в папке **examples**
#. Данные для обучения нейронных сетей в папке **data**\ , включая:

   #. стандартные архитектуры нейронных сетей (data/architectures) 
   #. обученные нейронные сети (data/trainedNN), в этой папке:

      * для каждого запуска обучения создаётся подпапка со следующими файлами:

        * Обученная модель (best_weights.h5)
        * Её схема (.png)
        * История обучения (.csv)
        * Результаты тестирования (.csv)
        * Конфигурация обучения (.json)

      * для каждого запуска подбора гиперпараметров создаётся подпапка со следующими файлами:

        * История подбора гиперпараметров (.csv)
        * Конфигурация подбора гиперпараметров (.json)
        * Подпапки с результатами обучения нейронных сетей, созданными в ходе подбора гиперпараметров

#. Вспомогательные скрипты в папке **scripts** для подготовки баз данных и их преобразованию в удобный формат  
#. Файлы для генерации документации в папке **docs**
#. Скрипты для запуска системы через различные интерфейсы:

   - launch.py -- запуск системы через веб-интерфейс (основной интерфейс)
   - launch_lm.py -- запуск обучения из командной строки с запросом на естественном языке, например
   - bot.py -- запуск телеграм-бота для отправки запросов на естественном языке через телеграм

Для работы системы также необходимо наличие следующих файлов и папок:


#. Папка **datasets** с датасетами, которые будут использоваться для обучения нейронных сетей
#. Папка **data/architectures** с файлами с дополнительных архитектур нейронных сетей, которые планируется использовать.
   и которые не входят в стандартный набор keras.applications.

Пакет ann_automl имеет следующие подмодули:

#. **core** -- ядро системы, работа с нейронными сетями и обучающими выборками
#. **nnplot** -- модуль для визуализации нейронных сетей, рисования различных графиков, связанных с обучением нейронных сетей
#. **gui** -- графический веб-интерфейс для работы с системой
#. **lm** -- функции работы с запросами на естественном языке
#. **utils** -- библиотека различных вспомогательных функций общего назначения
